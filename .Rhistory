sentiment = rep(0,anzahl_comments-1)
for(j in 2:anzahl_comments){
comment = content_array$comments$comment[j]
saetze = get_sentences(comment)
sentiment[j-1] = mean(get_sentiment(saetze))*content_array$comments$score[j] #weighted by score
}
return(mean(sentiment))
}
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)
}
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
try(thread_content = get_thread_content(gme_tibble_mean$URL[i]))
gme_tibble_mean$mean[i] = summarize_thread(thread_content)
}
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)}, finally ={})
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)}, finally ={})
}
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){print("Error")},
finally ={})
}
printf("%d", 5)
flush.console()
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
summ_err = 0
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
flush.console()
print(summ_err)
summ_err = summ_err + 1},
finally ={})
}
print('\r')
print('\r)
print('\r)
print(\r)
print(\r)
\r
print("\r ")
print(tets)
print("tets")
print("\r ")
print(\r summ_err)
print("\r"+ summ_err)
print("\r"_err)
print(summ_err + i)
print(summ_err + "von" + i)
print(summ_err/i)
i
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
summ_err = 0
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
flush.console()
summ_err = summ_err + 1
print(summ_err + i)
},
finally ={})
}
sprintf("%d" + "Hallo", 6)
sprintf(%d + "Hallo", 6)
sprintf(%s + "Hallo", 6)
sprintf("Hallo + %s", 10)
summ_err = 0
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
flush.console()
summ_err = summ_err + 1
sprintf("\r%s Erro im Lauf %s", summ_err, i)
},
finally ={})
}
summ_err = 0
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
flush.console()
summ_err = summ_err + 1
sprintf("%s Erro im Lauf %s\r", summ_err, i)
},
finally ={})
}
sprintf("%s Erro im Lauf %s", summ_err, i)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
flush.console()
summ_err = summ_err + 1
sprintf("%s Erro im Lauf %s", summ_err, i)
},
finally ={})
}
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
flush.console()
summ_err = summ_err + 1
print("hallo")
sprintf("%s Erro im Lauf %s", summ_err, i)
},
finally ={})
}
sprintf("%s Erro im Lauf %s", summ_err, i)
summ_err
string = 10 + "Test"
print(sprintf("%s Erro im Lauf %s", summ_err, i))
summ_err = 1
pb = txtProgressBar(min = 0, max = n, initial = 0, style = 3)
for (i in 1:n) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
summ_err = summ_err + 1
print(sprintf("%s Erro im Lauf %s", summ_err, i))
},
finally ={})
}
View(gme_tibble_mean)
for (i in 1:10) { # gehe durch alle threads
setTxtProgressBar(pb, i)
summ_err = 10 * tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
print(sprintf("%s Erro im Lauf %s", summ_err, i))
return(1)
},
finally ={})
}
summ_err = 1
for (i in 1:10) { # gehe durch alle threads
setTxtProgressBar(pb, i)
summ_err = 10 * tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
print(sprintf("%s Erro im Lauf %s", summ_err, i))
return(1)
},
finally ={})
}
sum(ends_with(data$url)
data %>% ends_with(".jpg")
data %>% ends_with(".jpg")
data$url %>% ends_with(".jpg")
select(data %>% ends_with(".jpg"))
select(data %>% ends_with(".jpg"))
data = data[-(endsWith(data$url, "jpg"))]
endsWith(data$url, "jpg")
data = data[!(endsWith(data$url, "jpg"))]
data = data[!(endsWith(data$url, "jpg"))]
data = data[!(endsWith(data$url, "jpg")),]
view(data)
data = data[!(endsWith(data$url, "png")),]
view(data)
write.csv(data, "pushshift_clean.csv")
write.csv(data, "pushshift_clean.csv")
##### Find Threads von python ----------
threads = read.csv("pushshift_clean.csv")
n = nrow(threads)
##### find threads--------
gme_tibble_mean = tibble(Date = threads$created_utc,
Count_of_Comments = threads$num_comments,
URL =  threads$url,
mean = rep(0))
anzahl_comments = nrow(content_array$comments)
##### analyse thread -----------
summarize_thread = function(content_array){
anzahl_comments = nrow(content_array$comments)
sentiment = rep(0,anzahl_comments-1)
for(j in 2:anzahl_comments){
comment = content_array$comments$comment[j]
saetze = get_sentences(comment)
sentiment[j-1] = mean(get_sentiment(saetze))*content_array$comments$score[j] #weighted by score
}
return(mean(sentiment))
}
pb = txtProgressBar(min = 0, max = 150, initial = 0, style = 3)
for (i in 1:150) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
print(sprintf("Erro im Lauf %s", i))
},
finally ={})
}
ggplot(data = gme_tibble_mean[1:150,])+
geom_point(mapping = aes(x = Date, y = mean, col = Count_of_Comments), show.legend = TRUE)+
scale_color_gradient(low="red", high="green")
fruit <- c("apple", "banana", "pear", "pinapple")
str_detect(fruit, "a")
data = data[str_detect(data$url, "comments")]
data = data[str_detect(data$url, "comments"),]
view(data)
data$url[100]
data %>% select(Count_of_Comments > 2)
names(data)
data %>% select(num_comments > 2)
data %>% select(data$num_comments > 2)
data %>% filter(data$num_comments > 2)
data = data %>% filter(data$num_comments > 2)
write.csv(data, "pushshift_clean.csv")
##### Find Threads von python ----------
threads = read.csv("pushshift_clean.csv")
n = nrow(threads)
##### find threads--------
gme_tibble_mean = tibble(Date = threads$created_utc,
Count_of_Comments = threads$num_comments,
URL =  threads$url,
mean = rep(0))
##### analyse thread -----------
summarize_thread = function(content_array){
anzahl_comments = nrow(content_array$comments)
sentiment = rep(0,anzahl_comments-1)
for(j in 2:anzahl_comments){
comment = content_array$comments$comment[j]
saetze = get_sentences(comment)
sentiment[j-1] = mean(get_sentiment(saetze))*content_array$comments$score[j] #weighted by score
}
return(mean(sentiment))
}
pb = txtProgressBar(min = 0, max = 150, initial = 0, style = 3)
for (i in 1:150) { # gehe durch alle threads
setTxtProgressBar(pb, i)
tryCatch(expr = {thread_content = get_thread_content(gme_tibble_mean$URL[i])
gme_tibble_mean$mean[i] = summarize_thread(thread_content)},
error = function(e){
print(sprintf("Erro im Lauf %s", i))
},
finally ={})
}
ggplot(data = gme_tibble_mean[1:150,])+
geom_point(mapping = aes(x = Date, y = mean, col = Count_of_Comments), show.legend = TRUE)+
scale_color_gradient(low="red", high="green")
data = read_csv("pushshift.csv")
data$created_utc = as.Date(as.POSIXct(data$created_utc, origin="1970-01-01"))
View(data)
summary(data$created_utc)
unique(data$created_utc)
library(tidyverse)
data = read_csv("pushshift.csv")
data$created_utc = as.Date(as.POSIXct(data$created_utc, origin="1970-01-01"))
data = select(data, -c(d_,created))
data = data[str_detect(data$url, "comments"),] #url ohne comment sind bilder/memes/videos
data = data %>% filter(data$num_comments > 2) ##weniger als 3 Kommentare entweder irrelvant, gelÃ¶scht oder Bot
dim(data)
Anzahl_Kommentare = sum(data$num_comments)
head(data)
boxplot(data$num_comments)
which.max(data$num_comments)
boxplot(data$num_comments)
data[ 7425, ]
data[ 7425, ]$url
hist(data$num_comments)
hist(data$num_comments, breaks = 10)
hist(data$num_comments, breaks = 100)
hist(data$num_comments, breaks = 1000)
hist(data$num_comments, breaks = 1000, xlim = 5000)
hist(data$num_comments, breaks = 1000, ylim = 5000)
hist(data$num_comments, breaks = 1000,xlim = 1:5000)
hist(data$num_comments, breaks = 1000,xlim = range(1,5000)
hist(data$num_comments, breaks = 1000,xlim = range(1,5000))
hist(data$num_comments, breaks = 1000,xlim = range(1,5000))
count(data %>% select(data$num_comments > 100))
count(data %>% filter(data$num_comments > 100))
count(data %>% filter(data$num_comments > 1000))
count(data %>% filter(data$num_comments > 10000))
count(data %>% filter(data$num_comments > 100000))
summary(data$num_comments)
quantile(data$num_comments)
quantile(data$num_comments, probs = 0.01)
quantile(data$num_comments, type = 9)
quantile(data$num_comments, probs = seq(0,1,by = 0.01))
quantile(data$num_comments, probs = seq(0,1,by = 0.1))
count(data %>% filter(data$num_comments > 100000))
count(data %>% filter(data$num_comments > 1000))
hist(data$num_comments,xlim = range(0,1000), breaks = 25)
data_under_1000 = data %>% filter(data$num_comments > 1000)
hist(data_under_1000 , breaks = 25)
hist(data_under_1000$num_comments , breaks = 25)
data_under_1000 = data %>% filter(data$num_comments > 1000)
hist(data_under_1000$num_comments , breaks = 25)
data_under_1000 = data %>% filter(data$num_comments < 1000)
hist(data_under_1000$num_comments , breaks = 25)
sum(data_under_1000$num_comments)
Anzahl_Kommentare
library(tidyverse)
names(data)
ggplot(data = data, mapping = aes(x = created_utc, y = num_comments))
ggplot(data = data, mapping = aes(x = created_utc, y = num_comments)) + geom_point(col= data$score)
ggplot(data = data, mapping = aes(x = created_utc, y = num_comments), col = score) + geom_point()
ggplot(data = data, mapping = aes(x = created_utc, y = num_comments), col = score) + geom_point(show.legend =  T)
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments), col = score) + geom_point(show.legend =  T)
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments), col = score) + geom_point(size = 0.1)
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments, col = score)) + geom_point(size = 0.1)
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments, col = score)) +
geom_point(size = 0.1) +
scale_color_gradient(low = "red", high ="green")
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments, col = score)) +
geom_point(size = 1) +
scale_color_gradient(low = "red", high ="green")
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments, col = score)) +
geom_point(size = 1) +
scale_color_gradient(low = "red", high ="blue")
data_over_1000 =  data %>% filter(data$num_comments > 1000)
hist(data_over_1000$num_comments , breaks = 25)
sum(data_over_1000$num_comments)
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments, col = score)) +
geom_point(size = 1) +
scale_color_gradient(low = "red", high ="blue")
ggplot(data = data_over_1000, mapping = aes(x = created_utc, y = num_comments, col = score)) +
geom_point(size = 1) +
scale_color_gradient(low = "red", high ="blue")
library(tidyverse)
data = read_csv("pushshift.csv")
data$created_utc = as.Date(as.POSIXct(data$created_utc, origin="1970-01-01"))
data = select(data, -c(d_,created))
ggplot(data = data, mapping = aes(x=created_utc, y = num_comments))+
geom_point()
data = data[str_detect(data$url, "comments"),] #url ohne comment sind bilder/memes/videos
data = data %>% filter(data$num_comments > 2) ##weniger als 3 Kommentare entweder irrelvant, gelÃ¶scht oder Bot
dim(data)
Anzahl_Kommentare = sum(data$num_comments)
write.csv(data, "pushshift_clean.csv")
### cleaning hier fertig, aber anzahl der kommentare mÃ¼ssen reduziert werden
head(data)
data_under_1000 = data %>% filter(data$num_comments < 1000)
data_over_1000 =  data %>% filter(data$num_comments > 1000)
hist(data_under_1000$num_comments , breaks = 10)
sum(data_under_1000$num_comments)
ggplot(data = data_under_1000, mapping = aes(x = created_utc, y = num_comments, col = score)) +
geom_point(size = 1) +
scale_color_gradient(low = "red", high ="blue")
data = read_csv("pushshift.csv")
library(tidyverse)
sentiment_frame = read_csv("gme_date_discrete.csv")
view(sentiment_frame)
sentiment_frame = sentiment_frame[,-1]
sentiment_frame
sentiment_frame = sentiment_frame %>% mutate(week_day = weekdays((Date)))
sentiment_frame
sentiment_frame = sentiment_frame
week_day_add =sentiment_frame %>% if (Date="Sonntag"){
return(2)
} else if(Date = "Samstag"){
return(3)
} else if(Date = "Freitag"){
return(4)
} else if(Date = "Donnerstag"){
return(4)
} else {
return(2)
}
week_day_add =sentiment_frame %>% if (Date="Sonntag"){
return(2)
} else if(Date = "Samstag"){
return(3)
} else if(Date = "Freitag"){
return(4)
} else if(Date = "Donnerstag"){
return(4)
} else {
return(2)
}
week_day_add = if (sentiment_frame$Date="Sonntag"){
return(2)
} else if(. = "Samstag"){
return(3)
} else if(Date = "Freitag"){
return(4)
} else if(Date = "Donnerstag"){
return(4)
} else {
return(2)
}
week_day_add = if (sentiment_frame$Date="Sonntag"){
return(2)
} else if(. = "Samstag"){
return(3)
} else if(Date = "Freitag"){
return(4)
} else if(Date = "Donnerstag"){
return(4)
} else {
return(2)
}
week_day_add = if (sentiment_frame$Date="Sonntag"){
2
} else if(. = "Samstag"){
3
} else if(Date = "Freitag"){
4
} else if(Date = "Donnerstag"){
4
} else {
2
}
week_day_add = if (sentiment_frame$Date="Sonntag"){
2
} else if(sentiment_frame$Date = "Samstag"){
3
} else if(sentiment_frame$Date = "Freitag"){
4
} else if(sentiment_frame$Date = "Donnerstag"){
4
} else {
2
}
week_day_add = rep(2,nrow(sentiment_frame))
week_day_add = if(sentiment_frame$Date = "Samstag") 3
3
week_day_add = if(sentiment_frame$Date = "Samstag"){
3
}
week_day_add = 3
week_day_add = rep(2,nrow(sentiment_frame))
week_day_add = if(sentiment_frame$Date = "Samstag"){
week_day_add = 3
}
week_day_add = rep(2,nrow(sentiment_frame))
week_day_add[sentiment_frame$Date = "Samstag"] = 3
week_day_add[sentiment_frame$Date == "Samstag"] = 3
sentiment_frame$Date == "Samstag"
sentiment_frame$week_day == "Samstag"
week_day_add[sentiment_frame$week_day == "Samstag"] = 3
sentiment_frame = read_csv("gme_date_discrete.csv")
sentiment_frame = sentiment_frame[,-1]
sentiment_frame = sentiment_frame %>% mutate(week_day = weekdays((Date)))
week_day_add = rep(2,nrow(sentiment_frame))
week_day_add[sentiment_frame$week_day == "Samstag"] = 3
week_day_add[sentiment_frame$week_day == "Freitag"] = 4
week_day_add[sentiment_frame$week_day == "Donnerstag"] = 4
sentiment_frame = sentiment_frame %>% mutate(week_day_add = week_day_add)
view(sentiment_frame)
sentiment_frame = sentiment_frame %>% mutate(day_to_pred = Date + week_day_add)
view(sentiment_frame)
write.csv(sentiment_frame, "sentiment_frame.csv")
#----Librarys
library(tidyverse)
gme_sap = read.csv(file = "controlls_and_gme.R")
gme_sap = read_csv(file = "controlls_and_gme.R")
#----Librarys
library(tidyverse)
gme_sap = read_csv(file = "controlls_and_gme.R")
gme_sap
gme_sap = read_csv(file = "Stock_Data.csv")
sentiment = read_csv(file = "sentiment_frame.csv")
sentiment = sentiment %>% select(-Data)
sentiment = sentiment %>% select(-Date)
sentiment
names(sentiment)
sentiment = sentiment %>% select(-c(Date,...1))
sentiment = read_csv(file = "sentiment_frame.csv")
sentiment = sentiment %>% select(-c(Date,...1))
sentiment = sentiment[,-1]
sentiment
full_data = inner_join(gme_sap, sentiment, by = c ("Date" = "day_to_pred"))
full_data
full_data = full_data %>% mutate(-c(Close.x, lag, Close.y, lag1, lag2,lag3))
full_data = full_data %>% select(-c(Close.x, lag, Close.y, lag1, lag2,lag3))
full_data
gme_sap = read_csv(file = "Stock_Data.csv")
sentiment = read_csv(file = "sentiment_frame.csv")
sentiment = sentiment %>% select(-Date)
sentiment = sentiment[,-1]
full_data = inner_join(gme_sap, sentiment, by = c ("Date" = "day_to_pred"))
full_data
full_data = full_data %>% select(-c(Close.x, lag, Close.y, lag1, lag2,lag3))
full_data
lm_reg = lm(formula = gme_change~mean +sum_com + mean*sum_com + sp_change  +lag(sp_change,1) + lag(sp_change, 2) + lag(sp_change, 3),
data = full_data)
summary(lm_reg)
plot(x = mean, y = gme_change, data = full_data)
plot(x = mean, y = gme_change, data = full_data)
ggplot(data = full_data) + geom_point(mapping = aes(x=mean, y = gme_change))
#---- Regression
lm_reg = lm(formula = gme_change~mean +sum_com + mean*sum_com, data = full_data)
summary(lm_reg)
summary(lm_reg)
ggplot(data = full_data) + geom_point(mapping = aes(x=mean, y = gme_change))
